需要解决的问题：
1. 当某个agent被删除以后，我希望在聊天框中该agent的消息不会被删除。

需要增加或改进的功能：
1. 在有大于1个agent存在于聊天群中的时候，会选取任意一个agent对用户的输入做出回答。这个agent首先需要在后端中从多个角度确定由多个agent讨论或是直接回答。选择由多个agent讨论时，发起讨论的agent需要根据用户提出的问题设置一个讨论的框架，例如将用户的问题分为一些子问题然后一个一个讨论这些子问题，或者设置前置问题然后一个一个讨论等等。讨论的框架不需要发到对话框中，但是由讨论框架产生的当前agent要解决的问题需要发到对话框中，后续回答的agent需要遵守第一个agent制定的框架，考虑解决框架提出的问题，然后对比框架提出问题的解决进度和用户的初始问题，判断是否需要停止讨论。注意：讨论是自动进行的，前一个agent发言完毕后，不需要用户操作，下一个agent自动开始讨论；在agent讨论进行的时候，位于输入框和对话框之间会出现一个悬浮框，中间有“讨论中”的字样，和一个表示暂停的按钮，按钮按下后，用户可以立刻停止agent的讨论，agent的讨论停止后，悬浮窗也消失。


需要改进辩论功能：agent需要明确哪个观点是其他agent提出的，哪个观点是自己拥护的（这一点可能需要在历史上下文功能中添加，表明发言人身份）。在多轮辩论中需要始终坚持自己的观点。不能反过来对自己持有的观点进行批判。



现在将后端和前端以及agent代码进行联合修改：
把非流式输出改成流式输出（stream=True），对于后端服务器和前端对话气泡框的部分，需要注意输出只能在一个气泡框中显示，另外，在气泡框中的内容还在更新的时候，表示加载中的加载圈同样应出现在同一个气泡框中，直到内容更新完毕时，加载圈消失。加载圈的样式和现有的保持一致。删除原来的加载气泡框。

上下文工程：
1. 多agent讨论的时候，agent的推理内容不计入历史上下文中，而是计入一个便笺中，agent根据便笺中的内容以及用户的要求进行讨论。便笺与上下文是分开的，只有agent讨论的结论内容计入上下文。在一次讨论结束后，便笺内容清空。在实现时，需要考虑多agent的读写问题，和中断讨论时，便笺数据丢失的问题

2. 对于用户的偏好，长期要求或重要结论等等，不计入历史上下文中，而是计入记忆（memory）中，这类信息一般长度偏短，但一些关键数据也可能需要长期记忆。agent需要在每次回答时，讨论时对这些记忆进行参考，参考的方式是，通过对记忆进行检索，向量检索：将用户问题转为向量，匹配语义相似的历史记忆（如 FAQ 库），关键词检索：通过规则匹配提取结构化数据（如订单号、时间戳）。可以考虑混合检索。

3. 实现压缩上下文，压缩时，借鉴 PageRank 网页排名算法，将文本中的句子视为 “节点”，通过句子间的相似度（关键词）构建网络，相似度越高的句子权重越高，最终选择高权重句子，在agent 处理后组成总结。上下文超过一定字数自动进行压缩操作。关于句子的相似度比较可以考虑更高效的计算方式（如TF-IDF + Cosine，或预训练的小型Sentence-BERT）除相似度外，可以加入时间衰减因子（新近句子权重更高）。

4. 使用文件实时储存agent对话上下文的功能，高频写入时需低延迟，避免文件锁竞争，能够处理意外中断（如进程崩溃）后的数据恢复。以上所有上下文工程的功能，都在ContextEngineering.py的文件中实现，用类包装，方便其他文件调用
